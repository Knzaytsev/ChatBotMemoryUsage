{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3b06aa-8bc6-4bc0-85f2-41456ca66573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, T5EncoderModel\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from model_classes import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "model = torch.load('best_classifier.pth').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/t5-xl-lm-adapt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b362e35-0154-4d2e-870a-c28ec0880cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('speakers_facts.json', 'r') as f:\n",
    "    annotated_data = json.loads(f.read())\n",
    "    \n",
    "with open('sess_ann_inputs.json', 'r') as f:\n",
    "    ann_inputs = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8082f4d8-04fa-4ea6-a045-ad7c650c049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_blank_facts = lambda x: [fact for fact in x if len(fact) >= 7 or not fact.endswith(':')]\n",
    "preprocess_fact = lambda x: re.sub(r'^[\\*\\d]+\\.?\\s+', '', x)\n",
    "speaker_mapper = {'facts_s1': 's1', 'facts_s2': 's2'}\n",
    "\n",
    "annotated_data = [{\n",
    "    'dialog_id': dialog['data']['dialog_id'],\n",
    "    'session': dialog['data']['session'],\n",
    "    'dialog': dialog['data']['dialogue'], \n",
    "    'correct_facts': {speaker_mapper[facts['from_name']]: remove_blank_facts([preprocess_fact(fact) for fact in facts['value']['choices']])\n",
    "                      for facts in dialog['annotations'][0]['result'] if facts['from_name'] in speaker_mapper.keys()},\n",
    "    'facts': {'s1': remove_blank_facts([preprocess_fact(fact['value']) for fact in dialog['data']['s1']]), \n",
    "              's2': remove_blank_facts([preprocess_fact(fact['value']) for fact in dialog['data']['s2']])},\n",
    "    'summary': dialog['data']['summary']\n",
    "        }\n",
    "    for dialog in annotated_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94cb451e-2eed-46ec-858e-da84d4d0b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_blank_facts = lambda x: [fact for fact in x if fact]\n",
    "# speaker_mapper = {'facts_s1': 's1', 'facts_s2': 's2'}\n",
    "\n",
    "# annotated_data = [{\n",
    "#     'dialog_id': dialog['data']['dialog_id'],\n",
    "#     'dialogue': dialog['data']['dialogue'], \n",
    "#     'correct_facts': {speaker_mapper[facts['from_name']]: facts['value']['choices'] \n",
    "#                       for facts in dialog['annotations'][0]['result']},\n",
    "#     'facts': {'s1': remove_blank_facts([fact['value'] for fact in dialog['data']['s1']]), \n",
    "#               's2': remove_blank_facts([fact['value'] for fact in dialog['data']['s2']])}\n",
    "#         }\n",
    "#     for dialog in annotated_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6b46fb9-e7b7-459c-873f-5b4fce856405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dialog(dialog):\n",
    "    return '\\n'.join([f\"{phrase['author']}: {phrase['text']}\" for phrase in dialog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7b88212-bc58-4674-9b77-315ce28d1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_dialog_concat(speaker, fact, dialog):\n",
    "    return '\\n\\n'.join(['\\n'.join([f'Fact about {speaker}:', fact]), dialog,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2edac239-75b6-4228-98f6-d033f74f0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_actual_facts(facts, model):\n",
    "    inputs = tokenizer(\n",
    "            facts, \n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=2048,\n",
    "        ).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = F.softmax(model(inputs, inputs.attention_mask).detach().cpu(), dim=1)[:, 1] > .65\n",
    "        \n",
    "    return outputs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "813cbf3f-5176-4e8e-a3d1-eac11aaebe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_actual_facts(speaker, facts, dialog, model):\n",
    "    facts = np.array(facts.copy())\n",
    "    input_data = [fact_dialog_concat(speaker, fact, convert_dialog(dialog)) for fact in facts]\n",
    "    actual_facts = predict_actual_facts(input_data, model)\n",
    "    return facts[actual_facts].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1f3133d-2f34-4b92-8fdc-a7b1008458d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = {(data['dialog_id'], data['session']): data for data in annotated_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc9850ed-9613-405a-b526-ae8796b12d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = {'s1': 'bot_0', 's2': 'bot_1'}\n",
    "\n",
    "extract_facts = lambda facts: [fact['value'] for fact in facts]\n",
    "extract_speaker_phrases = lambda speaker, dialog: [{'author': phrase['author'], 'text': phrase['text']} \n",
    "                                                   for phrase in dialog if phrase['author'] == speaker]\n",
    "\n",
    "ann_inputs = [\n",
    "    {\n",
    "        **ann, \n",
    "        **{\n",
    "            speaker: [{'value': fact} for fact in remove_blank_facts([preprocess_fact(fact['value']) for fact in ann[speaker]])] \n",
    "            for speaker in speakers.keys()\n",
    "        }\n",
    "    } \n",
    "    for ann in ann_inputs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "496c026f-1e12-4b28-babf-c93b9826e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [05:36<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = [\n",
    "    {'data': data,\n",
    "     'predictions': [\n",
    "         {'result': [result for result in [\n",
    "         {\n",
    "             'from_name': 'facts_' + f_speaker, \n",
    "             'to_name': 'chat',\n",
    "             'value': {'choices': choice_actual_facts(b_speaker, extract_facts(data[f_speaker]), \n",
    "                                                      extract_speaker_phrases(b_speaker, data['dialogue']), \n",
    "                                                      model)},\n",
    "             'type': 'choices',\n",
    "         }\n",
    "         for f_speaker, b_speaker in speakers.items()] if result['value']['choices']]}\n",
    "     ]\n",
    "    } \n",
    "    for data in tqdm(ann_inputs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da6a55c6-f6d6-4bb3-af0a-bccf6cb2bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prediction in predictions:\n",
    "    prediction['data']['is_annotated'] = (prediction['data']['dialog_id'], prediction['data']['session']) in annotated_data\n",
    "    \n",
    "    if (prediction['data']['dialog_id'], prediction['data']['session']) in annotated_data:\n",
    "        prediction['predictions'] = [\n",
    "            {'result': [\n",
    "                    {\n",
    "                        'from_name': 'facts_' + speaker, 'to_name': 'chat', 'value': {'choices': facts}, 'type': 'choices'\n",
    "                    }\n",
    "                for speaker, facts in annotated_data[(prediction['data']['dialog_id'], prediction['data']['session'])]['correct_facts'].items()\n",
    "            ] \n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2de24d59-600c-40c1-a850-c13ecade24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = [\n",
    "#     {'data': {'dialog': data['dialog'], **{speaker: [{'value': fact} \n",
    "#                                                      for fact in facts] \n",
    "#                                            for speaker, facts in data['facts'].items()}},\n",
    "#      'predictions': [\n",
    "#          {'result': [result for result in [\n",
    "#          {\n",
    "#              'from_name': 'facts_' + speaker, \n",
    "#              'to_name': 'chat',\n",
    "#              'value': {'choices': choice_actual_facts(speaker, facts, data['dialog'], model)},\n",
    "#              'type': 'choices',\n",
    "#          }\n",
    "#          for speaker, facts in data['facts'].items()] if result['value']['choices']]}\n",
    "#      ]\n",
    "#     } \n",
    "#     for data in sample_dialogs\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c341530a-94ef-4231-98e0-5c74d7eb2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions_vicuna.json', 'w') as f:\n",
    "    json.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ec7ee-a493-48aa-bbb0-b3c4ce0243e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
