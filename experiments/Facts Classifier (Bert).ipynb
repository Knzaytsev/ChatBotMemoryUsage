{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c1ee34-6116-4d76-bbb2-dab8330ef4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d64f59-cbb6-4ffe-b642-bc08f572d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kabita-choudhary/finetuned-bart-for-conversation-summary were not used when initializing BartForSequenceClassification: ['final_logits_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at kabita-choudhary/finetuned-bart-for-conversation-summary and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoConfig, BertForSequenceClassification, BartForSequenceClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kabita-choudhary/finetuned-bart-for-conversation-summary\", )\n",
    "\n",
    "model = BartForSequenceClassification.from_pretrained(\"kabita-choudhary/finetuned-bart-for-conversation-summary\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3c5bc2-0b3b-4a45-9a74-d19d4135967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7669d8-2afb-49e3-b6aa-dff875c12186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('speakers_facts.json', 'r') as f:\n",
    "    annotated_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada08ddc-5f76-40d8-b704-b3c324bcd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_blank_facts = lambda x: [fact for fact in x if len(fact) >= 7 or not fact.endswith(':')]\n",
    "preprocess_fact = lambda x: re.sub(r'^[\\*\\d]+\\.?\\s+', '', x)\n",
    "speaker_mapper = {'facts_s1': 's1', 'facts_s2': 's2'}\n",
    "\n",
    "annotated_data = [{\n",
    "    'dialog': dialog['data']['dialogue'], \n",
    "    'correct_facts': {speaker_mapper[facts['from_name']]: remove_blank_facts([preprocess_fact(fact) for fact in facts['value']['choices']])\n",
    "                      for facts in dialog['annotations'][0]['result'] if facts['from_name'] in speaker_mapper.keys()},\n",
    "    'facts': {'s1': remove_blank_facts([preprocess_fact(fact['value']) for fact in dialog['data']['s1']]), \n",
    "              's2': remove_blank_facts([preprocess_fact(fact['value']) for fact in dialog['data']['s2']])},\n",
    "    'summary': dialog['data']['summary']\n",
    "        }\n",
    "    for dialog in annotated_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ff282d-8031-4713-a98b-bc9dc124f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_mapper = {'s1': 'bot_0', 's2': 'bot_1'}\n",
    "\n",
    "facts_set = {'s1': [fact for data in annotated_data for fact in data['facts']['s1']], \n",
    "             's2': [fact for data in annotated_data for fact in data['facts']['s2']]}\n",
    "\n",
    "dataset = [{\n",
    "    'dialog': '\\n'.join([f'{phrase[\"author\"]}: {phrase[\"text\"]}' \n",
    "                         for phrase in dialog['dialog'] \n",
    "                        ]),\n",
    "    'speaker': speaker_mapper[speaker],\n",
    "    'fact': fact, \n",
    "    'target': fact in dialog['correct_facts'].get(speaker, []),\n",
    "    'summary': dialog['summary']\n",
    "} for dialog in annotated_data for speaker, facts in dialog['facts'].items() \n",
    "    for fact in facts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae49a217-fc34-48c0-8a59-884a8716de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ClassifierDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        sample = self.data[index]\n",
    "\n",
    "        context = '\\n\\n'.join(['\\n'.join([f'Fact about {sample[\"speaker\"]}:', sample['fact']]),\n",
    "                               sample['dialog'], ])\n",
    "        \n",
    "        target = sample['target']\n",
    "\n",
    "        return context, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d7026e-e55e-4335-a516-e720d0935b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collator:\n",
    "\n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, batch):\n",
    "\n",
    "        inputs = []\n",
    "        targets = []\n",
    "\n",
    "        for context, target in batch:\n",
    "            inputs.append(context)\n",
    "            targets.append(target)\n",
    "\n",
    "        tokenized_input = self.tokenizer(\n",
    "            inputs, \n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "\n",
    "        return tokenized_input, torch.LongTensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b55180-a8e5-4bcb-bfae-0ba803f6ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_dataset = ClassifierDataset(data=dataset[:int(len(dataset)*.8)])\n",
    "valid_dataset = ClassifierDataset(data=dataset[int(len(dataset)*.8):])\n",
    "\n",
    "collator = Collator(tokenizer=tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collator, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collator, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54262944-6284-4482-bed2-7a47af026308",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26b3fb0-e672-4e01-8ca5-9c6a9ae3cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def loop(n_epoch, is_train, criterion, optimizer, model, loader, grad_acum_steps=1):\n",
    "    \n",
    "    global_step = len(loader) // grad_acum_steps * n_epoch\n",
    "\n",
    "\n",
    "    all_predictions = list()\n",
    "    all_targets = list()\n",
    "\n",
    "    losses = list()\n",
    "    f1_scores = list()\n",
    "    accuracies = list()\n",
    "    rocs = list()\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader) // grad_acum_steps, desc=\"Train\" if is_train else \"Valid\")\n",
    "\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    losses = list()\n",
    "\n",
    "    for n_step, (batch, targets) in enumerate(loader):\n",
    "\n",
    "        batch = batch.to(model.device)\n",
    "        targets = targets.to(model.device)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(**batch).logits\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                logits = model(**batch).logits\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        f1_scores.append(f1_score(targets.detach().cpu(), \n",
    "                                  logits.detach().cpu().argmax(1), \n",
    "                                  zero_division=False))\n",
    "        accuracies.append(accuracy_score(targets.detach().cpu(), \n",
    "                                         logits.detach().cpu().argmax(1)))\n",
    "        \n",
    "        try:\n",
    "            rocs.append(roc_auc_score(targets.detach().cpu(), \n",
    "                                      F.softmax(logits.detach().cpu(), dim=1)[:, 1]))\n",
    "        except:\n",
    "            rocs.append(0)\n",
    "            pass\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=0.7)\n",
    "            optimizer.step()\n",
    "        progress_bar.update()\n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-100:]), \n",
    "                                 f1_score=np.mean(f1_scores[-100:]),\n",
    "                                 accuracy=np.mean(accuracies[-100:]), \n",
    "                                 roc_auc=np.mean(rocs[-100:]))\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    return losses, f1_scores, accuracies, rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2112ab6b-593d-430e-9ce3-719245a005f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "def define_model(trial):\n",
    "    pooling_type = \"mean\"\n",
    "    dropout = trial.suggest_float(\"dropout\", .1, .7)\n",
    "    normalize = trial.suggest_int(\"normalize\", False, True)\n",
    "    embedding_masking = trial.suggest_int(\"embedding_masking\", False, True)\n",
    "\n",
    "    pooling = GlobalMaskedPooling(pooling_type=pooling_type, normalize=normalize, \n",
    "                                  embedding_masking=embedding_masking)\n",
    "    classifier = Classifier(model, pooling, dropout, 2)\n",
    "    return classifier\n",
    "\n",
    "def get_dataset_loaders():\n",
    "    train_dataset = ClassifierDataset(data=dataset[:int(len(dataset)*.8)])\n",
    "    valid_dataset = ClassifierDataset(data=dataset[int(len(dataset)*.8):])\n",
    "\n",
    "    collator = Collator(tokenizer=tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collator, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collator, shuffle=True)\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def objective(trial):\n",
    "    model = define_model(trial).to('mps')\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-7, 1e-3, log=True)\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loader, valid_loader = get_dataset_loaders()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(model.device)\n",
    "            target = target.to(model.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data, data.attention_mask)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        f1_scores = list()\n",
    "        outputs = list()\n",
    "        targets = list()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                data = data.to(model.device)\n",
    "                target = target.to(model.device)\n",
    "\n",
    "                output = model(data, data.attention_mask)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.detach().cpu().argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.detach().cpu().view_as(pred)).sum().item()\n",
    "                \n",
    "                outputs.extend(F.softmax(output.detach().cpu(), dim=1)[:, 1])\n",
    "                targets.extend(target.detach().cpu())\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "        # f1 = f1_score(targets, outputs)\n",
    "        roc_auc = 0\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(targets, outputs)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "        trial.report(roc_auc, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0106afde-6407-4fc7-9dc5-8f4af3837e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=2e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42f6680-d089-40d3-9971-28eabf273b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  12%|█▏        | 80/677 [14:03<2:01:55, 12.25s/it, accuracy=0.456, f1_score=0.458, loss=0.715, roc_auc=0.237]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/88/77rz0tyn27s99tjty03mzhz80000gn/T/ipykernel_97645/1437268945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     train_losses, train_f1_scores, train_accuracies, train_roc_auc = loop(n_epoch, True, \n\u001b[0m\u001b[1;32m     13\u001b[0m                                                                           \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                                           \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/88/77rz0tyn27s99tjty03mzhz80000gn/T/ipykernel_97645/1035728040.py\u001b[0m in \u001b[0;36mloop\u001b[0;34m(n_epoch, is_train, criterion, optimizer, model, loader, grad_acum_steps)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             )\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 )\n\u001b[1;32m   1117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1119\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "best_valid_loss = np.inf\n",
    "losses = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "rocs = []\n",
    "\n",
    "for n_epoch in range(100):\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "    train_losses, train_f1_scores, train_accuracies, train_roc_auc = loop(n_epoch, True, \n",
    "                                                                          criterion,\n",
    "                                                                          optimizer, model, \n",
    "                                                                          loader=train_loader)\n",
    "    valid_losses, valid_f1_scores, valid_accuracies, valid_roc_auc = loop(n_epoch, False,\n",
    "                                                                          criterion,\n",
    "                                                                          optimizer, model,\n",
    "                                                                          loader=valid_loader)\n",
    "\n",
    "    train_mean_loss = np.mean(train_losses)\n",
    "    valid_mean_loss = np.mean(valid_losses)\n",
    "\n",
    "    train_mean_f1_scores = np.mean(train_f1_scores)\n",
    "    valid_mean_f1_scores = np.mean(valid_f1_scores)\n",
    "\n",
    "    train_mean_accuracies = np.mean(train_accuracies)\n",
    "    valid_mean_accuracies = np.mean(valid_accuracies)\n",
    "    \n",
    "    train_mean_roc_auc = np.mean(train_roc_auc)\n",
    "    valid_mean_roc_auc = np.mean(valid_roc_auc)\n",
    "    \n",
    "    losses.append(valid_mean_loss)\n",
    "    f1_scores.append(valid_mean_f1_scores)\n",
    "    accuracies.append(valid_mean_accuracies)\n",
    "    rocs.append(valid_mean_roc_auc)\n",
    "\n",
    "    epoch_message = [\n",
    "        f\"Epoch {n_epoch} done\",\n",
    "        \"\",\n",
    "        \"Train\",\n",
    "        f\"\\tLoss: {train_mean_loss:.3f}\",\n",
    "        f\"\\tF1-score: {train_mean_f1_scores:.3f}\",\n",
    "        f\"\\tAccuracy: {train_mean_accuracies:.3f}\",\n",
    "        f\"\\tROC AUC: {train_mean_roc_auc:.3f}\",\n",
    "        \"Valid\",\n",
    "        f\"\\tLoss: {valid_mean_loss:.3f}\",\n",
    "        f\"\\tF1-score: {valid_mean_f1_scores:.3f}\",\n",
    "        f\"\\tAccuracy: {valid_mean_accuracies:.3f}\",\n",
    "        f\"\\tROC AUC: {valid_mean_roc_auc:.3f}\",\n",
    "    ]\n",
    "\n",
    "    print(\"\\n\".join(epoch_message))\n",
    "    \n",
    "    if valid_mean_loss > np.mean(losses) or np.isnan(np.mean(losses)):\n",
    "        print('early stop')\n",
    "        break\n",
    "\n",
    "    if valid_mean_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_mean_loss\n",
    "        torch.save(model, \"best_classifier.pth\")\n",
    "        \n",
    "torch.save(model, \"last_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc0cb46-53bd-41c4-9a35-ab223324ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torch.load('best_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3522ebd8-9c9a-4bc3-ad57-f703f4a4603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step_threshold = 3\n",
    "min_threshold, max_threshold = 40, 80\n",
    "\n",
    "f1_results = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "roc_aucs = []\n",
    "\n",
    "thresholds_range = range(min_threshold, max_threshold, step_threshold)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y_hats = []\n",
    "y_true = []\n",
    "for n_step, (batch, targets) in enumerate(valid_loader):\n",
    "\n",
    "    batch = batch.to(classifier.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**batch).logits\n",
    "\n",
    "    outputs = F.softmax(logits.detach().cpu(), dim=1)[:, 1]\n",
    "    \n",
    "    y_hats.extend(outputs.tolist())\n",
    "    y_true.extend(targets.tolist())\n",
    "\n",
    "for i in thresholds_range:\n",
    "    thresholded_y_hats = np.array(y_hats) > i / 100\n",
    "    f1_results.append(f1_score(y_true, thresholded_y_hats))\n",
    "    accuracies.append(accuracy_score(y_true, thresholded_y_hats))\n",
    "    precisions.append(precision_score(y_true, thresholded_y_hats))\n",
    "    recalls.append(recall_score(y_true, thresholded_y_hats))\n",
    "    roc_aucs.append(roc_auc_score(y_true, thresholded_y_hats))\n",
    "    \n",
    "plt.plot(thresholds_range, f1_results, label='f1-score')\n",
    "plt.plot(thresholds_range, accuracies, label='accuracy')\n",
    "plt.plot(thresholds_range, precisions, label='precision')\n",
    "plt.plot(thresholds_range, recalls, label='recall')\n",
    "plt.plot(thresholds_range, roc_aucs, label='roc-auc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "090dc977-91d8-456b-8df5-2a01f76c645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "samples = sample(dataset[-50:], 10)\n",
    "processed_samples = ['\\n\\n'.join(['\\n'.join([f'Fact about {random_sample[\"speaker\"]}:', \n",
    "                                          random_sample['fact']]), \n",
    "                                  random_sample['dialog'],]) for random_sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "107f33ae-5fff-4899-8edf-e3b0776f9e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact about bot_1:\n",
      "bot_1 mentioned that they majored in computer science in college.\n",
      "\n",
      "bot_0: I like to have money to spend. What is the quickest way to be as rich as you?\n",
      "bot_1: I inherited some money and used it to develop my company. So I would say that you should find your passion and do what you can to profit from it.\n",
      "bot_0: Thats good advice.  My only passion right now is helping shelter pets.  I feel so sad that people overlook them because they're not a designer breed.  When are you heading back to Paris?\n",
      "bot_1: I think you can definitely find a way to make a lot of money by helping animals! Going to college might be a way you can find your passion helping animals. I'm planning on taking my sister there for her birthday.\n",
      "bot_0: I guess a business degree isn't the worst idea in the world.  I wish I had a sibling who would take me to Paris.  So jealous.  Any special plans while you are there?\n",
      "bot_1: Lol just regular touristy things. We'll probably go to some cafes, shop around, and visit the Eiffel tower. \n",
      "bot_0: There's nothing wrong with that.  I'd probably do the same thing....and eat a lot of cheese.  How's your hockey team doing this year?\n",
      "bot_1: I'll definitely put eating cheese on our to-do list while we're there. Not off to the greatest start, but I have hope they'll pull through. \n",
      "bot_0: I've tried watching hockey on tv but I can't get into it.  Plus, it's hard to follow the puck on the ice.  Why isn't your other sister going to Paris with you?\n",
      "bot_1: Yeah, I think hockey is one of those sports that you either love or can't get into. She's going, but she's getting there a little later than us because she couldn't get extra days off of work. \n",
      "bot_0: Hey, at least she's going.  I'd be thrilled to just spend 24 hours in the city.  What did you major in at college?\n",
      "bot_1: Yeah we couldn't celebrate a birthday without her! I majored in computer science.\n"
     ]
    }
   ],
   "source": [
    "print(processed_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "badec630-a168-496f-91cf-ffa0a27e370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "            processed_samples, \n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=2048,\n",
    "        ).to(classifier.device)\n",
    "with torch.no_grad():\n",
    "    outputs = classifier(inputs, inputs.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68f6cc89-ef04-4e2a-9f15-88ee2b5fb42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6270, 0.6219, 0.6200, 0.5939, 0.6520, 0.6129, 0.5939, 0.5895, 0.6030,\n",
       "        0.5751])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(outputs.detach().cpu(), dim=1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e5c60c3-f33a-4fb8-af9c-833fd54af190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(random_sample['target']) for random_sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48b8d04a-b686-4df7-9330-a3e358fdc196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score([int(random_sample['target']) for random_sample in samples], F.softmax(outputs.detach().cpu(), dim=1)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cbc76-ffdc-4457-9deb-aa2d3a1021ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 - (100 * .1) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103203c-b731-4f34-a2ae-4baa22587584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 / 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
