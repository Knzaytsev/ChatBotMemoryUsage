{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad67e19-b088-466a-be36-aa0d1e85d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef716ae1-06fd-45be-8d8b-1e02a308baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vicuna_experiments/vicuna_context/answers_with_context.json', 'r') as f:\n",
    "    with_context = json.loads(f.read())\n",
    "    \n",
    "with open('vicuna_experiments/vicuna_without_context/answers_without_context.json', 'r') as f:\n",
    "    without_context = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4292397b-7fd1-4eb3-aefe-865ac9605715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Context:\\n1. The Assistant has vision problems and has called 911 in the past due to severe headaches.\\n2. The Assistant used to have six cats and is now married to a friend from high school.\\n3. The Human is from Virginia and is not currently married.\\n\\n Facts about Human:\\nHuman is not married and lives in Virginia.\\n\\nFacts about Assistant:\\nWorks from home\\nHas trouble seeing\\nHas 200 feet vision\\nGets bad headaches\\nHas called 911 before\\nUsed to have 6 cats\\nLives in Alaska\\nAssistant has vision problems and gets headaches.\\nAssistant is from Alaska and got married to a friend from high school.\\n\\n Dialog:\\nHuman: How are you and your cats doing today over in Alaska?\\nAssistant: Good thanks. How are you and your dad in Virginia? \\nHuman: We are doing pretty good thank you for asking. I hope you don't have any headaches today!\\nAssistant: I am having a headache right now. My vision is messed up and I can hardly see. \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bfc2029-3bc0-429c-ac27-3783ec12628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_fix = lambda x: [row for row in x.split('\\n') if row]\n",
    "\n",
    "collected_answers = [{'context': split_and_fix(context_dialog)[-1], 'simple': split_and_fix(simple_dialog)[-1]} \n",
    "                     for context_dialog, simple_dialog in zip(with_context, without_context)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "168c0a43-b122-42c4-9f74-16584887b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dialogs = [dialog.replace(answers['context'], '') for dialog, answers in zip(with_context, collected_answers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57b498bf-8c87-43ef-8487-d18c33c5b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_answers(context_answer, simple_answer):\n",
    "    from random import shuffle\n",
    "    \n",
    "    answers = [context_answer, simple_answer]\n",
    "    shuffle(answers)\n",
    "\n",
    "    if answers[0] == context_answer:\n",
    "        contexted_answer = 'Answer A'\n",
    "    else:\n",
    "        contexted_answer = 'Answer B'\n",
    "    \n",
    "    return {'Answer A': answers[0], 'Answer B': answers[1], 'Contexted Answer': contexted_answer}\n",
    "\n",
    "annotation_dataset = [{'dialog': dialog, **shuffle_answers(answers['context'], answers['simple'])} \n",
    "                      for dialog, answers in zip(cleaned_dialogs, collected_answers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6b65431-621d-4f2b-8441-50832fe8a45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200*90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "507831bf-7b42-41b3-af42-7fb15c439f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vicuna_experiments/annotation_dataset.json', 'w') as f:\n",
    "    json.dump(annotation_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9c14fd-d7aa-49ce-b7ae-9243ea41c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vicuna_experiments/annotation_dataset.json', 'r') as f:\n",
    "    annotation_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fed6090-4bf7-4c8b-ab33-aa28cf060709",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vicuna_experiments/annotated_data.jsonl', 'r') as f:\n",
    "    annotated_data = f.readlines()\n",
    "    annotated_data = [json.loads(data) for data in annotated_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf049650-6a78-463a-8c42-1a6424bc00f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5838926174496645"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([data['Answer'] == data['Contexted Answer'] or data['Answer'] == 'Both answers are relevant' \n",
    "     for data in annotated_data]) / len(annotated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d17f6b9-9c0f-4e54-9d3b-541e4c2243de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5897435897435898"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([data['Answer'] == data['Contexted Answer'] for data in annotated_data]) /  \\\n",
    "        len([data for data in annotated_data if data['Answer'] in ['Answer A', 'Answer B']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670827c6-ba00-459b-8a74-4edd78d20637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "1. Assistant enjoys eating meat and mentions riding in a black sexy car with their pet panda.\n",
      "2. Human mentions liking cheddar on their biscuits and riding a bike.\n",
      "3. Human also mentions being an insurance salesman and having heightened senses and knowledge.\n",
      "* Human is interested in seeing Assistant's Kung Fu Panda, Chewy.\n",
      "* Human is available to meet up later that night to grill out and meet Chewy.\n",
      "* Human is looking forward to meeting Chewy.\n",
      "\n",
      " Facts about Human:\n",
      "Human likes cheddar cheese on biscuits\n",
      "Human enjoys riding bikes\n",
      "Human is an insurance salesman\n",
      "Human has heightened senses and knowledge\n",
      "Human is interested in visiting Chewy the panda\n",
      "Human's bike is currently being repaired and they are unable to ride over to see Chewy\n",
      "Human is free to visit Chewy tonight and will bring a salad to contribute to dinner\n",
      "\n",
      "Facts about Assistant:\n",
      "Assistant has insurance for their car but not for their pet panda because the panda knows martial arts\n",
      "Assistant enjoys listening to rap music.\n",
      "Assistant is a panda named Chewy.\n",
      "Assistant is a limo driver and takes care of Chewy\n",
      "\n",
      " Dialog:\n",
      "Human: You'll never believe this, I just sold car insurance to this guy who doesn't have a car! \n",
      "Assistant: wow! you must be the best insurance salesman ever. Maybe i should buy my car insurance from you\n",
      "Human: hOW DID YOU WRITE DOWN THE MAKE AND MODEL? iS IT ONE HE WANTS TO BUY IN FUTURE?\n",
      "Assistant: I was giving a person a lift in my limo the other day. we were discussing insurance and he said that he was intrested in a new bike. what kind of bike do you have?\n",
      "Human: How do you like driving a limo? \n",
      "Assistant: I enjoy it a lot. I get to meet a lot of interesting people. Sometimes i have to chauffeur celebrities!\n",
      "Human: That would be something I would love to do. Who have you met that is famous?\n",
      "\n",
      "\n",
      "Answer A:\n",
      " Assistant: Ive driven for Jay-Z and Kanye West. I also chauffeured a woman who was the singer from some pop-group you may have heard before!\n",
      "Answer B:\n",
      " Assistant: I met a famous chef on my last trip. I also had another passenger who is a well known chef. he was on his way to a cooking competition.\n",
      "Contexted Answer:\n",
      " Answer B\n"
     ]
    }
   ],
   "source": [
    "idx = 46\n",
    "print(annotation_data[idx]['dialog'])\n",
    "print('Answer A:\\n', annotation_data[idx]['Answer A'])\n",
    "print('Answer B:\\n', annotation_data[idx]['Answer B'])\n",
    "print('Contexted Answer:\\n', annotation_data[idx]['Contexted Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3399b-b8f3-4f19-b2c5-7e0aabc4ffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
