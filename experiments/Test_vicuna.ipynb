{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e8511e-4bc4-44d7-ada4-403ad90868c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import SentencePieceProcessor\n",
    "from logging import getLogger\n",
    "from typing import List\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        # reload tokenizer\n",
    "        assert os.path.isfile(model_path), model_path\n",
    "        self.sp_model = SentencePieceProcessor(model_file=model_path)\n",
    "        logger.info(f\"Reloaded SentencePiece model from {model_path}\")\n",
    "\n",
    "        # BOS / EOS token IDs\n",
    "        self.n_words: int = self.sp_model.vocab_size()\n",
    "        self.bos_id: int = self.sp_model.bos_id()\n",
    "        self.eos_id: int = self.sp_model.eos_id()\n",
    "        self.pad_id: int = self.sp_model.pad_id()\n",
    "        logger.info(\n",
    "            f\"#words: {self.n_words} - BOS ID: {self.bos_id} - EOS ID: {self.eos_id}\"\n",
    "        )\n",
    "        assert self.sp_model.vocab_size() == self.sp_model.get_piece_size()\n",
    "\n",
    "    def encode(self, s: str, bos: bool, eos: bool) -> List[int]:\n",
    "        assert type(s) is str\n",
    "        t = self.sp_model.encode(s)\n",
    "        if bos:\n",
    "            t = [self.bos_id] + t\n",
    "        if eos:\n",
    "            t = t + [self.eos_id]\n",
    "        return t\n",
    "\n",
    "    def decode(self, t: List[int]) -> str:\n",
    "        return self.sp_model.decode(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e069de-8c45-44b1-9528-53ed2e804e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cb14b55-4492-4017-94d7-587dc2e9a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sess_outputs.json', 'r') as f:\n",
    "    output = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26d32034-8858-4798-b0a7-e2b071532dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6010f6e7-1592-463b-b725-f69bcbe49204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * bot_1 is a musician and a teacher at a middle school in New York City\n",
      "* bot_1 has been blogging and creating YouTube content for nearly a decade\n",
      "* bot_1 has been offering tutoring math services, which earns passive income\n",
      "* bot_1 has been offering advice to bot_0 on side income opportunities\n",
      "* bot_1 suggests that bot_0 should blog and teach music for side income\n",
      "* bot_1 advises bot_0 to start blogging and earning passive income through math tutoring\n",
      "* bot_1 plans to continue blogging and creating YouTube content in addition to teaching full-time\n",
      "* bot_1 encourages bot_0 to pursue a career in music and to work towards getting a record deal.\n"
     ]
    }
   ],
   "source": [
    "print(output[20]['session_3']['facts']['bot_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135f478-bde1-4e9c-9d18-6c488ffd01b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a215bc78456434296737c4c81e59044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1bd44dcd874c899d5e2e26a875ad61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6826e6a37046a9a3f4f21e117e1aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4638901455404c9c27ac30f2fab175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"samwit/vicuna-13b-8bit\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"samwit/vicuna-13b-8bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a4cb1-553c-47d1-94dd-0d0ba2bd6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"eachadea/vicuna-13b-1.1\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"eachadea/vicuna-7b-1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55acf7d4-9459-4e9f-8eef-c5f4b0c76748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer('./LLaMA_tokenizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f42790-df7d-4b13-a9c2-c663ab840f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"</s> Human: Write poem about linux\\n</s> Assistant:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d98fc4e-b9d4-4f0e-a838-428fe3fe0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.encode(text, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b784af7c-7b80-43e2-84fe-fba2310e3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8740bac-79ba-4d0a-a46b-3b5301bb7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = torch.tensor([tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ae7866-89d4-46e9-810a-a5d382ee3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_indices = model.generate(input_ids=tokenized, max_new_tokens=12).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59ed2e0-8d82-4bed-b1e0-52ac7034ea96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s> Human: Write poem about linux\\n</s> Assistant: Home / News / News / The Best of the Best'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_indices[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a5b6e-3dba-45e4-a767-55af9392d894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
